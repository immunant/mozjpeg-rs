use ::libc;

pub use crate::stddef_h::size_t;
pub use crate::stddef_h::NULL;
pub use crate::stdlib::_IO_codecvt;
pub use crate::stdlib::_IO_lock_t;
pub use crate::stdlib::_IO_marker;
pub use crate::stdlib::_IO_wide_data;
pub use crate::stdlib::__off64_t;
pub use crate::stdlib::__off_t;
pub use crate::stdlib::FILE;
pub use crate::stdlib::_IO_FILE;

pub use crate::jmemsys_h::backing_store_info;
pub use crate::jmemsys_h::backing_store_ptr;
pub use crate::jmemsys_h::backing_store_struct;
pub use crate::jmemsys_h::MAX_ALLOC_CHUNK;
pub use crate::jmorecfg_h::boolean;
pub use crate::jmorecfg_h::FALSE;
pub use crate::jmorecfg_h::JCOEF;
pub use crate::jmorecfg_h::JDIMENSION;
pub use crate::jmorecfg_h::JSAMPLE;
pub use crate::jmorecfg_h::TRUE;
pub use crate::jpeglib_h::j_common_ptr;
pub use crate::jpeglib_h::jpeg_common_struct;
pub use crate::jpeglib_h::jpeg_error_mgr;
pub use crate::jpeglib_h::jpeg_memory_mgr;
pub use crate::jpeglib_h::jpeg_progress_mgr;
pub use crate::jpeglib_h::jvirt_barray_ptr;
pub use crate::jpeglib_h::jvirt_sarray_ptr;
pub use crate::jpeglib_h::C2RustUnnamed_2;
pub use crate::jpeglib_h::JBLOCK;
pub use crate::jpeglib_h::JBLOCKARRAY;
pub use crate::jpeglib_h::JBLOCKROW;
pub use crate::jpeglib_h::JPOOL_IMAGE;
pub use crate::jpeglib_h::JPOOL_NUMPOOLS;
pub use crate::jpeglib_h::JPOOL_PERMANENT;
pub use crate::jpeglib_h::JSAMPARRAY;
pub use crate::jpeglib_h::JSAMPROW;
pub use crate::src::jerror::JERR_ARITH_NOTIMPL;
pub use crate::src::jerror::JERR_BAD_ALIGN_TYPE;
pub use crate::src::jerror::JERR_BAD_ALLOC_CHUNK;
pub use crate::src::jerror::JERR_BAD_BUFFER_MODE;
pub use crate::src::jerror::JERR_BAD_COMPONENT_ID;
pub use crate::src::jerror::JERR_BAD_CROP_SPEC;
pub use crate::src::jerror::JERR_BAD_DCTSIZE;
pub use crate::src::jerror::JERR_BAD_DCT_COEF;
pub use crate::src::jerror::JERR_BAD_HUFF_TABLE;
pub use crate::src::jerror::JERR_BAD_IN_COLORSPACE;
pub use crate::src::jerror::JERR_BAD_J_COLORSPACE;
pub use crate::src::jerror::JERR_BAD_LENGTH;
pub use crate::src::jerror::JERR_BAD_LIB_VERSION;
pub use crate::src::jerror::JERR_BAD_MCU_SIZE;
pub use crate::src::jerror::JERR_BAD_PARAM;
pub use crate::src::jerror::JERR_BAD_PARAM_VALUE;
pub use crate::src::jerror::JERR_BAD_POOL_ID;
pub use crate::src::jerror::JERR_BAD_PRECISION;
pub use crate::src::jerror::JERR_BAD_PROGRESSION;
pub use crate::src::jerror::JERR_BAD_PROG_SCRIPT;
pub use crate::src::jerror::JERR_BAD_SAMPLING;
pub use crate::src::jerror::JERR_BAD_SCAN_SCRIPT;
pub use crate::src::jerror::JERR_BAD_STATE;
pub use crate::src::jerror::JERR_BAD_STRUCT_SIZE;
pub use crate::src::jerror::JERR_BAD_VIRTUAL_ACCESS;
pub use crate::src::jerror::JERR_BUFFER_SIZE;
pub use crate::src::jerror::JERR_CANT_SUSPEND;
pub use crate::src::jerror::JERR_CCIR601_NOTIMPL;
pub use crate::src::jerror::JERR_COMPONENT_COUNT;
pub use crate::src::jerror::JERR_CONVERSION_NOTIMPL;
pub use crate::src::jerror::JERR_DAC_INDEX;
pub use crate::src::jerror::JERR_DAC_VALUE;
pub use crate::src::jerror::JERR_DHT_INDEX;
pub use crate::src::jerror::JERR_DQT_INDEX;
pub use crate::src::jerror::JERR_EMPTY_IMAGE;
pub use crate::src::jerror::JERR_EMS_READ;
pub use crate::src::jerror::JERR_EMS_WRITE;
pub use crate::src::jerror::JERR_EOI_EXPECTED;
pub use crate::src::jerror::JERR_FILE_READ;
pub use crate::src::jerror::JERR_FILE_WRITE;
pub use crate::src::jerror::JERR_FRACT_SAMPLE_NOTIMPL;
pub use crate::src::jerror::JERR_HUFF_CLEN_OVERFLOW;
pub use crate::src::jerror::JERR_HUFF_MISSING_CODE;
pub use crate::src::jerror::JERR_IMAGE_TOO_BIG;
pub use crate::src::jerror::JERR_INPUT_EMPTY;
pub use crate::src::jerror::JERR_INPUT_EOF;
pub use crate::src::jerror::JERR_MISMATCHED_QUANT_TABLE;
pub use crate::src::jerror::JERR_MISSING_DATA;
pub use crate::src::jerror::JERR_MODE_CHANGE;
pub use crate::src::jerror::JERR_NOTIMPL;
pub use crate::src::jerror::JERR_NOT_COMPILED;
pub use crate::src::jerror::JERR_NO_BACKING_STORE;
pub use crate::src::jerror::JERR_NO_HUFF_TABLE;
pub use crate::src::jerror::JERR_NO_IMAGE;
pub use crate::src::jerror::JERR_NO_QUANT_TABLE;
pub use crate::src::jerror::JERR_NO_SOI;
pub use crate::src::jerror::JERR_OUT_OF_MEMORY;
pub use crate::src::jerror::JERR_QUANT_COMPONENTS;
pub use crate::src::jerror::JERR_QUANT_FEW_COLORS;
pub use crate::src::jerror::JERR_QUANT_MANY_COLORS;
pub use crate::src::jerror::JERR_SOF_DUPLICATE;
pub use crate::src::jerror::JERR_SOF_NO_SOS;
pub use crate::src::jerror::JERR_SOF_UNSUPPORTED;
pub use crate::src::jerror::JERR_SOI_DUPLICATE;
pub use crate::src::jerror::JERR_SOS_NO_SOF;
pub use crate::src::jerror::JERR_TFILE_CREATE;
pub use crate::src::jerror::JERR_TFILE_READ;
pub use crate::src::jerror::JERR_TFILE_SEEK;
pub use crate::src::jerror::JERR_TFILE_WRITE;
pub use crate::src::jerror::JERR_TOO_LITTLE_DATA;
pub use crate::src::jerror::JERR_UNKNOWN_MARKER;
pub use crate::src::jerror::JERR_UNSUPPORTED_SUSPEND;
pub use crate::src::jerror::JERR_VIRTUAL_BUG;
pub use crate::src::jerror::JERR_WIDTH_OVERFLOW;
pub use crate::src::jerror::JERR_XMS_READ;
pub use crate::src::jerror::JERR_XMS_WRITE;
pub use crate::src::jerror::JMSG_COPYRIGHT;
pub use crate::src::jerror::JMSG_LASTMSGCODE;
pub use crate::src::jerror::JMSG_NOMESSAGE;
pub use crate::src::jerror::JMSG_VERSION;
pub use crate::src::jerror::JTRC_16BIT_TABLES;
pub use crate::src::jerror::JTRC_ADOBE;
pub use crate::src::jerror::JTRC_APP0;
pub use crate::src::jerror::JTRC_APP14;
pub use crate::src::jerror::JTRC_DAC;
pub use crate::src::jerror::JTRC_DHT;
pub use crate::src::jerror::JTRC_DQT;
pub use crate::src::jerror::JTRC_DRI;
pub use crate::src::jerror::JTRC_EMS_CLOSE;
pub use crate::src::jerror::JTRC_EMS_OPEN;
pub use crate::src::jerror::JTRC_EOI;
pub use crate::src::jerror::JTRC_HUFFBITS;
pub use crate::src::jerror::JTRC_JFIF;
pub use crate::src::jerror::JTRC_JFIF_BADTHUMBNAILSIZE;
pub use crate::src::jerror::JTRC_JFIF_EXTENSION;
pub use crate::src::jerror::JTRC_JFIF_THUMBNAIL;
pub use crate::src::jerror::JTRC_MISC_MARKER;
pub use crate::src::jerror::JTRC_PARMLESS_MARKER;
pub use crate::src::jerror::JTRC_QUANTVALS;
pub use crate::src::jerror::JTRC_QUANT_3_NCOLORS;
pub use crate::src::jerror::JTRC_QUANT_NCOLORS;
pub use crate::src::jerror::JTRC_QUANT_SELECTED;
pub use crate::src::jerror::JTRC_RECOVERY_ACTION;
pub use crate::src::jerror::JTRC_RST;
pub use crate::src::jerror::JTRC_SMOOTH_NOTIMPL;
pub use crate::src::jerror::JTRC_SOF;
pub use crate::src::jerror::JTRC_SOF_COMPONENT;
pub use crate::src::jerror::JTRC_SOI;
pub use crate::src::jerror::JTRC_SOS;
pub use crate::src::jerror::JTRC_SOS_COMPONENT;
pub use crate::src::jerror::JTRC_SOS_PARAMS;
pub use crate::src::jerror::JTRC_TFILE_CLOSE;
pub use crate::src::jerror::JTRC_TFILE_OPEN;
pub use crate::src::jerror::JTRC_THUMB_JPEG;
pub use crate::src::jerror::JTRC_THUMB_PALETTE;
pub use crate::src::jerror::JTRC_THUMB_RGB;
pub use crate::src::jerror::JTRC_UNKNOWN_IDS;
pub use crate::src::jerror::JTRC_XMS_CLOSE;
pub use crate::src::jerror::JTRC_XMS_OPEN;
pub use crate::src::jerror::JWRN_ADOBE_XFORM;
pub use crate::src::jerror::JWRN_BOGUS_ICC;
pub use crate::src::jerror::JWRN_BOGUS_PROGRESSION;
pub use crate::src::jerror::JWRN_EXTRANEOUS_DATA;
pub use crate::src::jerror::JWRN_HIT_MARKER;
pub use crate::src::jerror::JWRN_HUFF_BAD_CODE;
pub use crate::src::jerror::JWRN_JFIF_MAJOR;
pub use crate::src::jerror::JWRN_JPEG_EOF;
pub use crate::src::jerror::JWRN_MUST_RESYNC;
pub use crate::src::jerror::JWRN_NOT_SEQUENTIAL;
pub use crate::src::jerror::JWRN_TOO_MUCH_DATA;
pub use crate::src::jmemnobs::jpeg_free_large;
pub use crate::src::jmemnobs::jpeg_free_small;
pub use crate::src::jmemnobs::jpeg_get_large;
pub use crate::src::jmemnobs::jpeg_get_small;
pub use crate::src::jmemnobs::jpeg_mem_available;
pub use crate::src::jmemnobs::jpeg_mem_init;
pub use crate::src::jmemnobs::jpeg_mem_term;
pub use crate::src::jmemnobs::jpeg_open_backing_store;
use crate::src::jutils::jzero_far;
use crate::stdlib::getenv;
use crate::stdlib::sscanf;
pub use crate::stdlib::C2RustUnnamed_0;
pub use crate::stdlib::SIZE_MAX;
/* System-dependent control info */

#[repr(C)]
#[derive(Copy, Clone)]
pub struct jvirt_barray_control {
    pub mem_buffer: crate::jpeglib_h::JBLOCKARRAY,
    pub rows_in_array: crate::jmorecfg_h::JDIMENSION,
    pub blocksperrow: crate::jmorecfg_h::JDIMENSION,
    pub maxaccess: crate::jmorecfg_h::JDIMENSION,
    pub rows_in_mem: crate::jmorecfg_h::JDIMENSION,
    pub rowsperchunk: crate::jmorecfg_h::JDIMENSION,
    pub cur_start_row: crate::jmorecfg_h::JDIMENSION,
    pub first_undef_row: crate::jmorecfg_h::JDIMENSION,
    pub pre_zero: crate::jmorecfg_h::boolean,
    pub dirty: crate::jmorecfg_h::boolean,
    pub b_s_open: crate::jmorecfg_h::boolean,
    pub next: crate::jpeglib_h::jvirt_barray_ptr,
    pub b_s_info: crate::jmemsys_h::backing_store_info,
}
/*
 * The control blocks for virtual arrays.
 * Note that these blocks are allocated in the "small" pool area.
 * System-dependent info for the associated backing store (if any) is hidden
 * inside the backing_store_info struct.
 */

#[repr(C)]
#[derive(Copy, Clone)]
pub struct jvirt_sarray_control {
    pub mem_buffer: crate::jpeglib_h::JSAMPARRAY,
    pub rows_in_array: crate::jmorecfg_h::JDIMENSION,
    pub samplesperrow: crate::jmorecfg_h::JDIMENSION,
    pub maxaccess: crate::jmorecfg_h::JDIMENSION,
    pub rows_in_mem: crate::jmorecfg_h::JDIMENSION,
    pub rowsperchunk: crate::jmorecfg_h::JDIMENSION,
    pub cur_start_row: crate::jmorecfg_h::JDIMENSION,
    pub first_undef_row: crate::jmorecfg_h::JDIMENSION,
    pub pre_zero: crate::jmorecfg_h::boolean,
    pub dirty: crate::jmorecfg_h::boolean,
    pub b_s_open: crate::jmorecfg_h::boolean,
    pub next: crate::jpeglib_h::jvirt_sarray_ptr,
    pub b_s_info: crate::jmemsys_h::backing_store_info,
}

pub type my_mem_ptr = *mut my_memory_mgr;

#[repr(C)]
#[derive(Copy, Clone)]
pub struct my_memory_mgr {
    pub pub_0: crate::jpeglib_h::jpeg_memory_mgr,
    pub small_list: [small_pool_ptr; 2],
    pub large_list: [large_pool_ptr; 2],
    pub virt_sarray_list: crate::jpeglib_h::jvirt_sarray_ptr,
    pub virt_barray_list: crate::jpeglib_h::jvirt_barray_ptr,
    pub total_space_allocated: crate::stddef_h::size_t,
    pub last_rowsperchunk: crate::jmorecfg_h::JDIMENSION,
}

pub type large_pool_ptr = *mut large_pool_struct;

#[repr(C)]
#[derive(Copy, Clone)]
pub struct large_pool_struct {
    pub next: large_pool_ptr,
    pub bytes_used: crate::stddef_h::size_t,
    pub bytes_left: crate::stddef_h::size_t,
}
/* Most of the SIMD instructions we support require
16-byte (128-bit) alignment, but AVX2 requires
32-byte alignment. */
/*
 * We allocate objects from "pools", where each pool is gotten with a single
 * request to jpeg_get_small() or jpeg_get_large().  There is no per-object
 * overhead within a pool, except for alignment padding.  Each pool has a
 * header with a link to the next pool of the same class.
 * Small and large pool headers are identical.
 */

pub type small_pool_ptr = *mut small_pool_struct;

#[repr(C)]
#[derive(Copy, Clone)]
pub struct small_pool_struct {
    pub next: small_pool_ptr,
    pub bytes_used: crate::stddef_h::size_t,
    pub bytes_left: crate::stddef_h::size_t,
}

pub type small_pool_hdr = small_pool_struct;

pub type large_pool_hdr = large_pool_struct;
/* next in list of pools */
/* how many bytes already used within pool */
/* bytes still available in this pool */
/* next in list of pools */
/* how many bytes already used within pool */
/* bytes still available in this pool */
/*
 * jmemmgr.c
 *
 * This file was part of the Independent JPEG Group's software:
 * Copyright (C) 1991-1997, Thomas G. Lane.
 * libjpeg-turbo Modifications:
 * Copyright (C) 2016, D. R. Commander.
 * For conditions of distribution and use, see the accompanying README.ijg
 * file.
 *
 * This file contains the JPEG system-independent memory management
 * routines.  This code is usable across a wide variety of machines; most
 * of the system dependencies have been isolated in a separate file.
 * The major functions provided here are:
 *   * pool-based allocation and freeing of memory;
 *   * policy decisions about how to divide available memory among the
 *     virtual arrays;
 *   * control logic for swapping virtual arrays between main memory and
 *     backing storage.
 * The separate system-dependent file provides the actual backing-storage
 * access code, and it contains the policy decision about how much total
 * main memory to use.
 * This file is system-dependent in the sense that some of its functions
 * are unnecessary in some systems.  For example, if there is enough virtual
 * memory so that backing storage will never be used, much of the virtual
 * array control logic could be removed.  (Of course, if you have that much
 * memory then you shouldn't care about a little bit of unused code...)
 */
/* we define jvirt_Xarray_control structs */
/* <stdlib.h> should declare getenv() */

unsafe extern "C" fn round_up_pow2(
    mut a: crate::stddef_h::size_t,
    mut b: crate::stddef_h::size_t,
) -> crate::stddef_h::size_t
/* a rounded up to the next multiple of b, i.e. ceil(a/b)*b */
/* Assumes a >= 0, b > 0, and b is a power of 2 */ {
    return a
        .wrapping_add(b)
        .wrapping_sub(1 as libc::c_int as libc::c_ulong)
        & !b.wrapping_sub(1 as libc::c_int as libc::c_ulong);
}
/*
 * Some important notes:
 *   The allocation routines provided here must never return NULL.
 *   They should exit to error_exit if unsuccessful.
 *
 *   It's not a good idea to try to merge the sarray and barray routines,
 *   even though they are textually almost the same, because samples are
 *   usually stored as bytes while coefficients are shorts or ints.  Thus,
 *   in machines where byte pointers have a different representation from
 *   word pointers, the resulting machine code could not be the same.
 */
/*
 * Many machines require storage alignment: longs must start on 4-byte
 * boundaries, doubles on 8-byte boundaries, etc.  On such machines, malloc()
 * always returns pointers that are multiples of the worst-case alignment
 * requirement, and we had better do so too.
 * There isn't any really portable way to determine the worst-case alignment
 * requirement.  This module assumes that the alignment requirement is
 * multiples of ALIGN_SIZE.
 * By default, we define ALIGN_SIZE as sizeof(double).  This is necessary on
 * some workstations (where doubles really do need 8-byte alignment) and will
 * work fine on nearly everything.  If your machine has lesser alignment needs,
 * you can save a few bytes by making ALIGN_SIZE smaller.
 * The only place I know of where this will NOT work is certain Macintosh
 * 680x0 compilers that define double as a 10-byte IEEE extended float.
 * Doing 10-byte alignment is counterproductive because longwords won't be
 * aligned well.  Put "#define ALIGN_SIZE 4" in jconfig.h if you have
 * such a compiler.
 */
/* so can override from jconfig.h */

pub const ALIGN_SIZE: libc::c_int = 32 as libc::c_int;
/* System-dependent control info */
/* optional extra stuff for statistics */
/* MEM_STATS */

unsafe extern "C" fn out_of_memory(
    mut cinfo: crate::jpeglib_h::j_common_ptr,
    mut which: libc::c_int,
)
/* Report an out-of-memory error and stop execution */
/* If we compiled MEM_STATS support, report alloc requests before dying */
{
    (*(*cinfo).err).msg_code = crate::src::jerror::JERR_OUT_OF_MEMORY as libc::c_int;
    (*(*cinfo).err).msg_parm.i[0 as libc::c_int as usize] = which;
    Some(
        (*(*cinfo).err)
            .error_exit
            .expect("non-null function pointer"),
    )
    .expect("non-null function pointer")(cinfo);
}
/*
 * Allocation of "small" objects.
 *
 * For these, we use pooled storage.  When a new pool must be created,
 * we try to get enough space for the current request plus a "slop" factor,
 * where the slop will be the amount of leftover space in the new pool.
 * The speed vs. space tradeoff is largely determined by the slop values.
 * A different slop value is provided for each pool class (lifetime),
 * and we also distinguish the first pool of a class from later ones.
 * NOTE: the values given work fairly well on both 16- and 32-bit-int
 * machines, but may be too small if longs are 64 bits or more.
 *
 * Since we do not know what alignment malloc() gives us, we have to
 * allocate ALIGN_SIZE-1 extra space per pool to have room for alignment
 * adjustment.
 */

static mut first_pool_slop: [crate::stddef_h::size_t; 2] = [
    1600 as libc::c_int as crate::stddef_h::size_t,
    16000 as libc::c_int as crate::stddef_h::size_t,
];

static mut extra_pool_slop: [crate::stddef_h::size_t; 2] = [
    0 as libc::c_int as crate::stddef_h::size_t,
    5000 as libc::c_int as crate::stddef_h::size_t,
];

pub const MIN_SLOP: libc::c_int = 50 as libc::c_int;
/* greater than 0 to avoid futile looping */

unsafe extern "C" fn alloc_small(
    mut cinfo: crate::jpeglib_h::j_common_ptr,
    mut pool_id: libc::c_int,
    mut sizeofobject: crate::stddef_h::size_t,
) -> *mut libc::c_void
/* Allocate a "small" object */ {
    let mut mem: my_mem_ptr = (*cinfo).mem as my_mem_ptr;
    let mut hdr_ptr: small_pool_ptr = 0 as *mut small_pool_struct;
    let mut prev_hdr_ptr: small_pool_ptr = 0 as *mut small_pool_struct;
    let mut data_ptr: *mut libc::c_char = 0 as *mut libc::c_char;
    let mut min_request: crate::stddef_h::size_t = 0;
    let mut slop: crate::stddef_h::size_t = 0;
    /*
     * Round up the requested size to a multiple of ALIGN_SIZE in order
     * to assure alignment for the next object allocated in the same pool
     * and so that algorithms can straddle outside the proper area up
     * to the next alignment.
     */
    if sizeofobject > crate::jmemsys_h::MAX_ALLOC_CHUNK as libc::c_ulong {
        /* This prevents overflow/wrap-around in round_up_pow2() if sizeofobject
        is close to SIZE_MAX. */
        out_of_memory(cinfo, 7 as libc::c_int);
    }
    sizeofobject = round_up_pow2(sizeofobject, ALIGN_SIZE as crate::stddef_h::size_t);
    /* Check for unsatisfiable request (do now to ensure no overflow below) */
    if (::std::mem::size_of::<small_pool_hdr>() as libc::c_ulong)
        .wrapping_add(sizeofobject)
        .wrapping_add(ALIGN_SIZE as libc::c_ulong)
        .wrapping_sub(1 as libc::c_int as libc::c_ulong)
        > crate::jmemsys_h::MAX_ALLOC_CHUNK as libc::c_ulong
    {
        out_of_memory(cinfo, 1 as libc::c_int); /* request exceeds malloc's ability */
    }
    /* See if space is available in any existing pool */
    if pool_id < 0 as libc::c_int || pool_id >= crate::jpeglib_h::JPOOL_NUMPOOLS {
        (*(*cinfo).err).msg_code = crate::src::jerror::JERR_BAD_POOL_ID as libc::c_int; /* safety check */
        (*(*cinfo).err).msg_parm.i[0 as libc::c_int as usize] = pool_id; /* found pool with enough space */
        Some(
            (*(*cinfo).err)
                .error_exit
                .expect("non-null function pointer"),
        )
        .expect("non-null function pointer")(cinfo);
    }
    prev_hdr_ptr = crate::stddef_h::NULL as small_pool_ptr;
    hdr_ptr = (*mem).small_list[pool_id as usize];
    while !hdr_ptr.is_null() {
        if (*hdr_ptr).bytes_left >= sizeofobject {
            break;
        }
        prev_hdr_ptr = hdr_ptr;
        hdr_ptr = (*hdr_ptr).next
    }
    /* Time to make a new pool? */
    if hdr_ptr.is_null() {
        /* min_request is what we need now, slop is what will be leftover */
        min_request = (::std::mem::size_of::<small_pool_hdr>() as libc::c_ulong)
            .wrapping_add(sizeofobject)
            .wrapping_add(ALIGN_SIZE as libc::c_ulong)
            .wrapping_sub(1 as libc::c_int as libc::c_ulong);
        if prev_hdr_ptr.is_null() {
            /* first pool in class? */
            slop = first_pool_slop[pool_id as usize]
        } else {
            slop = extra_pool_slop[pool_id as usize]
        }
        /* Don't ask for more than MAX_ALLOC_CHUNK */
        if slop > (crate::jmemsys_h::MAX_ALLOC_CHUNK as libc::c_ulong).wrapping_sub(min_request) {
            slop = (crate::jmemsys_h::MAX_ALLOC_CHUNK as libc::c_ulong).wrapping_sub(min_request)
        }
        loop
        /* Try to get space, if fail reduce slop and try again */
        {
            hdr_ptr = crate::src::jmemnobs::jpeg_get_small(cinfo, min_request.wrapping_add(slop))
                as small_pool_ptr;
            if !hdr_ptr.is_null() {
                break;
            }
            slop = (slop as libc::c_ulong).wrapping_div(2 as libc::c_int as libc::c_ulong)
                as crate::stddef_h::size_t as crate::stddef_h::size_t;
            if slop < MIN_SLOP as libc::c_ulong {
                /* give up when it gets real small */
                out_of_memory(cinfo, 2 as libc::c_int);
            }
        }
        (*mem).total_space_allocated = ((*mem).total_space_allocated as libc::c_ulong)
            .wrapping_add(min_request.wrapping_add(slop))
            as crate::stddef_h::size_t
            as crate::stddef_h::size_t;
        /* Success, initialize the new pool header and add to end of list */
        (*hdr_ptr).next = crate::stddef_h::NULL as small_pool_ptr;
        (*hdr_ptr).bytes_used = 0 as libc::c_int as crate::stddef_h::size_t;
        (*hdr_ptr).bytes_left = sizeofobject.wrapping_add(slop);
        if prev_hdr_ptr.is_null() {
            /* first pool in class? */
            (*mem).small_list[pool_id as usize] = hdr_ptr
        } else {
            (*prev_hdr_ptr).next = hdr_ptr
        }
    }
    /* OK, allocate the object from the current pool */
    data_ptr = hdr_ptr as *mut libc::c_char; /* point to first data byte in pool... */
    data_ptr = data_ptr.offset(::std::mem::size_of::<small_pool_hdr>() as libc::c_ulong as isize); /* ...by skipping the header... */
    if (data_ptr as crate::stddef_h::size_t).wrapping_rem(ALIGN_SIZE as libc::c_ulong) != 0 {
        /* ...and adjust for alignment */
        data_ptr = data_ptr.offset((ALIGN_SIZE as libc::c_ulong).wrapping_sub(
            (data_ptr as crate::stddef_h::size_t).wrapping_rem(ALIGN_SIZE as libc::c_ulong),
        ) as isize)
    } /* point to place for object */
    data_ptr = data_ptr.offset((*hdr_ptr).bytes_used as isize);
    (*hdr_ptr).bytes_used = ((*hdr_ptr).bytes_used as libc::c_ulong).wrapping_add(sizeofobject)
        as crate::stddef_h::size_t as crate::stddef_h::size_t;
    (*hdr_ptr).bytes_left = ((*hdr_ptr).bytes_left as libc::c_ulong).wrapping_sub(sizeofobject)
        as crate::stddef_h::size_t as crate::stddef_h::size_t;
    return data_ptr as *mut libc::c_void;
}
/*
 * Allocation of "large" objects.
 *
 * The external semantics of these are the same as "small" objects.  However,
 * the pool management heuristics are quite different.  We assume that each
 * request is large enough that it may as well be passed directly to
 * jpeg_get_large; the pool management just links everything together
 * so that we can free it all on demand.
 * Note: the major use of "large" objects is in JSAMPARRAY and JBLOCKARRAY
 * structures.  The routines that create these structures (see below)
 * deliberately bunch rows together to ensure a large request size.
 */

unsafe extern "C" fn alloc_large(
    mut cinfo: crate::jpeglib_h::j_common_ptr,
    mut pool_id: libc::c_int,
    mut sizeofobject: crate::stddef_h::size_t,
) -> *mut libc::c_void
/* Allocate a "large" object */ {
    let mut mem: my_mem_ptr = (*cinfo).mem as my_mem_ptr;
    let mut hdr_ptr: large_pool_ptr = 0 as *mut large_pool_struct;
    let mut data_ptr: *mut libc::c_char = 0 as *mut libc::c_char;
    /*
     * Round up the requested size to a multiple of ALIGN_SIZE so that
     * algorithms can straddle outside the proper area up to the next
     * alignment.
     */
    if sizeofobject > crate::jmemsys_h::MAX_ALLOC_CHUNK as libc::c_ulong {
        /* This prevents overflow/wrap-around in round_up_pow2() if sizeofobject
        is close to SIZE_MAX. */
        out_of_memory(cinfo, 8 as libc::c_int);
    }
    sizeofobject = round_up_pow2(sizeofobject, ALIGN_SIZE as crate::stddef_h::size_t);
    /* Check for unsatisfiable request (do now to ensure no overflow below) */
    if (::std::mem::size_of::<large_pool_hdr>() as libc::c_ulong)
        .wrapping_add(sizeofobject)
        .wrapping_add(ALIGN_SIZE as libc::c_ulong)
        .wrapping_sub(1 as libc::c_int as libc::c_ulong)
        > crate::jmemsys_h::MAX_ALLOC_CHUNK as libc::c_ulong
    {
        out_of_memory(cinfo, 3 as libc::c_int); /* request exceeds malloc's ability */
    }
    /* Always make a new pool */
    if pool_id < 0 as libc::c_int || pool_id >= crate::jpeglib_h::JPOOL_NUMPOOLS {
        (*(*cinfo).err).msg_code = crate::src::jerror::JERR_BAD_POOL_ID as libc::c_int; /* safety check */
        (*(*cinfo).err).msg_parm.i[0 as libc::c_int as usize] = pool_id; /* jpeg_get_large failed */
        Some(
            (*(*cinfo).err)
                .error_exit
                .expect("non-null function pointer"),
        )
        .expect("non-null function pointer")(cinfo);
    }
    hdr_ptr = crate::src::jmemnobs::jpeg_get_large(
        cinfo,
        sizeofobject
            .wrapping_add(::std::mem::size_of::<large_pool_hdr>() as libc::c_ulong)
            .wrapping_add(ALIGN_SIZE as libc::c_ulong)
            .wrapping_sub(1 as libc::c_int as libc::c_ulong),
    ) as large_pool_ptr;
    if hdr_ptr.is_null() {
        out_of_memory(cinfo, 4 as libc::c_int);
    }
    (*mem).total_space_allocated = ((*mem).total_space_allocated as libc::c_ulong).wrapping_add(
        sizeofobject
            .wrapping_add(::std::mem::size_of::<large_pool_hdr>() as libc::c_ulong)
            .wrapping_add(ALIGN_SIZE as libc::c_ulong)
            .wrapping_sub(1 as libc::c_int as libc::c_ulong),
    ) as crate::stddef_h::size_t as crate::stddef_h::size_t;
    /* Success, initialize the new pool header and add to list */
    (*hdr_ptr).next = (*mem).large_list[pool_id as usize];
    /* We maintain space counts in each pool header for statistical purposes,
     * even though they are not needed for allocation.
     */
    (*hdr_ptr).bytes_used = sizeofobject; /* point to first data byte in pool... */
    (*hdr_ptr).bytes_left = 0 as libc::c_int as crate::stddef_h::size_t; /* ...by skipping the header... */
    (*mem).large_list[pool_id as usize] = hdr_ptr;
    data_ptr = hdr_ptr as *mut libc::c_char;
    data_ptr = data_ptr.offset(::std::mem::size_of::<small_pool_hdr>() as libc::c_ulong as isize);
    if (data_ptr as crate::stddef_h::size_t).wrapping_rem(ALIGN_SIZE as libc::c_ulong) != 0 {
        /* ...and adjust for alignment */
        data_ptr = data_ptr.offset((ALIGN_SIZE as libc::c_ulong).wrapping_sub(
            (data_ptr as crate::stddef_h::size_t).wrapping_rem(ALIGN_SIZE as libc::c_ulong),
        ) as isize)
    }
    return data_ptr as *mut libc::c_void;
}
/*
 * Creation of 2-D sample arrays.
 *
 * To minimize allocation overhead and to allow I/O of large contiguous
 * blocks, we allocate the sample rows in groups of as many rows as possible
 * without exceeding MAX_ALLOC_CHUNK total bytes per allocation request.
 * NB: the virtual array control routines, later in this file, know about
 * this chunking of rows.  The rowsperchunk value is left in the mem manager
 * object so that it can be saved away if this sarray is the workspace for
 * a virtual array.
 *
 * Since we are often upsampling with a factor 2, we align the size (not
 * the start) to 2 * ALIGN_SIZE so that the upsampling routines don't have
 * to be as careful about size.
 */

unsafe extern "C" fn alloc_sarray(
    mut cinfo: crate::jpeglib_h::j_common_ptr,
    mut pool_id: libc::c_int,
    mut samplesperrow: crate::jmorecfg_h::JDIMENSION,
    mut numrows: crate::jmorecfg_h::JDIMENSION,
) -> crate::jpeglib_h::JSAMPARRAY
/* Allocate a 2-D sample array */ {
    let mut mem: my_mem_ptr = (*cinfo).mem as my_mem_ptr;
    let mut result: crate::jpeglib_h::JSAMPARRAY = 0 as *mut crate::jpeglib_h::JSAMPROW;
    let mut workspace: crate::jpeglib_h::JSAMPROW = 0 as *mut crate::jmorecfg_h::JSAMPLE;
    let mut rowsperchunk: crate::jmorecfg_h::JDIMENSION = 0;
    let mut currow: crate::jmorecfg_h::JDIMENSION = 0;
    let mut i: crate::jmorecfg_h::JDIMENSION = 0;
    let mut ltemp: libc::c_long = 0;
    /* Make sure each row is properly aligned */
    if (ALIGN_SIZE as libc::c_ulong)
        .wrapping_rem(::std::mem::size_of::<crate::jmorecfg_h::JSAMPLE>() as libc::c_ulong)
        != 0 as libc::c_int as libc::c_ulong
    {
        out_of_memory(cinfo, 5 as libc::c_int); /* safety check */
    }
    if samplesperrow as libc::c_long > crate::jmemsys_h::MAX_ALLOC_CHUNK {
        /* This prevents overflow/wrap-around in round_up_pow2() if sizeofobject
        is close to SIZE_MAX. */
        out_of_memory(cinfo, 9 as libc::c_int);
    }
    samplesperrow = round_up_pow2(
        samplesperrow as crate::stddef_h::size_t,
        ((2 as libc::c_int * ALIGN_SIZE) as libc::c_ulong)
            .wrapping_div(::std::mem::size_of::<crate::jmorecfg_h::JSAMPLE>() as libc::c_ulong),
    ) as crate::jmorecfg_h::JDIMENSION;
    /* Calculate max # of rows allowed in one allocation chunk */
    ltemp = (crate::jmemsys_h::MAX_ALLOC_CHUNK as libc::c_ulong)
        .wrapping_sub(::std::mem::size_of::<large_pool_hdr>() as libc::c_ulong)
        .wrapping_div(
            (samplesperrow as libc::c_long as libc::c_ulong)
                .wrapping_mul(::std::mem::size_of::<crate::jmorecfg_h::JSAMPLE>() as libc::c_ulong),
        ) as libc::c_long;
    if ltemp <= 0 as libc::c_int as libc::c_long {
        (*(*cinfo).err).msg_code = crate::src::jerror::JERR_WIDTH_OVERFLOW as libc::c_int;
        Some(
            (*(*cinfo).err)
                .error_exit
                .expect("non-null function pointer"),
        )
        .expect("non-null function pointer")(cinfo);
    }
    if ltemp < numrows as libc::c_long {
        rowsperchunk = ltemp as crate::jmorecfg_h::JDIMENSION
    } else {
        rowsperchunk = numrows
    }
    (*mem).last_rowsperchunk = rowsperchunk;
    /* Get space for row pointers (small object) */
    result = alloc_small(
        cinfo,
        pool_id,
        (numrows as libc::c_ulong)
            .wrapping_mul(::std::mem::size_of::<crate::jpeglib_h::JSAMPROW>() as libc::c_ulong),
    ) as crate::jpeglib_h::JSAMPARRAY;
    /* Get the rows themselves (large objects) */
    currow = 0 as libc::c_int as crate::jmorecfg_h::JDIMENSION;
    while currow < numrows {
        rowsperchunk = if rowsperchunk < numrows.wrapping_sub(currow) {
            rowsperchunk
        } else {
            numrows.wrapping_sub(currow)
        };
        workspace = alloc_large(
            cinfo,
            pool_id,
            (rowsperchunk as crate::stddef_h::size_t)
                .wrapping_mul(samplesperrow as crate::stddef_h::size_t)
                .wrapping_mul(::std::mem::size_of::<crate::jmorecfg_h::JSAMPLE>() as libc::c_ulong),
        ) as crate::jpeglib_h::JSAMPROW;
        i = rowsperchunk;
        while i > 0 as libc::c_int as libc::c_uint {
            let fresh0 = currow;
            currow = currow.wrapping_add(1);
            let ref mut fresh1 = *result.offset(fresh0 as isize);
            *fresh1 = workspace;
            workspace = workspace.offset(samplesperrow as isize);
            i = i.wrapping_sub(1)
        }
    }
    return result;
}
/*
 * Creation of 2-D coefficient-block arrays.
 * This is essentially the same as the code for sample arrays, above.
 */

unsafe extern "C" fn alloc_barray(
    mut cinfo: crate::jpeglib_h::j_common_ptr,
    mut pool_id: libc::c_int,
    mut blocksperrow: crate::jmorecfg_h::JDIMENSION,
    mut numrows: crate::jmorecfg_h::JDIMENSION,
) -> crate::jpeglib_h::JBLOCKARRAY
/* Allocate a 2-D coefficient-block array */ {
    let mut mem: my_mem_ptr = (*cinfo).mem as my_mem_ptr;
    let mut result: crate::jpeglib_h::JBLOCKARRAY = 0 as *mut crate::jpeglib_h::JBLOCKROW;
    let mut workspace: crate::jpeglib_h::JBLOCKROW = 0 as *mut crate::jpeglib_h::JBLOCK;
    let mut rowsperchunk: crate::jmorecfg_h::JDIMENSION = 0;
    let mut currow: crate::jmorecfg_h::JDIMENSION = 0;
    let mut i: crate::jmorecfg_h::JDIMENSION = 0;
    let mut ltemp: libc::c_long = 0;
    /* Make sure each row is properly aligned */
    if (::std::mem::size_of::<crate::jpeglib_h::JBLOCK>() as libc::c_ulong)
        .wrapping_rem(ALIGN_SIZE as libc::c_ulong)
        != 0 as libc::c_int as libc::c_ulong
    {
        out_of_memory(cinfo, 6 as libc::c_int); /* safety check */
    }
    /* Calculate max # of rows allowed in one allocation chunk */
    ltemp = (crate::jmemsys_h::MAX_ALLOC_CHUNK as libc::c_ulong)
        .wrapping_sub(::std::mem::size_of::<large_pool_hdr>() as libc::c_ulong)
        .wrapping_div(
            (blocksperrow as libc::c_long as libc::c_ulong)
                .wrapping_mul(::std::mem::size_of::<crate::jpeglib_h::JBLOCK>() as libc::c_ulong),
        ) as libc::c_long;
    if ltemp <= 0 as libc::c_int as libc::c_long {
        (*(*cinfo).err).msg_code = crate::src::jerror::JERR_WIDTH_OVERFLOW as libc::c_int;
        Some(
            (*(*cinfo).err)
                .error_exit
                .expect("non-null function pointer"),
        )
        .expect("non-null function pointer")(cinfo);
    }
    if ltemp < numrows as libc::c_long {
        rowsperchunk = ltemp as crate::jmorecfg_h::JDIMENSION
    } else {
        rowsperchunk = numrows
    }
    (*mem).last_rowsperchunk = rowsperchunk;
    /* Get space for row pointers (small object) */
    result = alloc_small(
        cinfo,
        pool_id,
        (numrows as libc::c_ulong)
            .wrapping_mul(::std::mem::size_of::<crate::jpeglib_h::JBLOCKROW>() as libc::c_ulong),
    ) as crate::jpeglib_h::JBLOCKARRAY;
    /* Get the rows themselves (large objects) */
    currow = 0 as libc::c_int as crate::jmorecfg_h::JDIMENSION;
    while currow < numrows {
        rowsperchunk = if rowsperchunk < numrows.wrapping_sub(currow) {
            rowsperchunk
        } else {
            numrows.wrapping_sub(currow)
        };
        workspace = alloc_large(
            cinfo,
            pool_id,
            (rowsperchunk as crate::stddef_h::size_t)
                .wrapping_mul(blocksperrow as crate::stddef_h::size_t)
                .wrapping_mul(::std::mem::size_of::<crate::jpeglib_h::JBLOCK>() as libc::c_ulong),
        ) as crate::jpeglib_h::JBLOCKROW;
        i = rowsperchunk;
        while i > 0 as libc::c_int as libc::c_uint {
            let fresh2 = currow;
            currow = currow.wrapping_add(1);
            let ref mut fresh3 = *result.offset(fresh2 as isize);
            *fresh3 = workspace;
            workspace = workspace.offset(blocksperrow as isize);
            i = i.wrapping_sub(1)
        }
    }
    return result;
}
/*
 * About virtual array management:
 *
 * The above "normal" array routines are only used to allocate strip buffers
 * (as wide as the image, but just a few rows high).  Full-image-sized buffers
 * are handled as "virtual" arrays.  The array is still accessed a strip at a
 * time, but the memory manager must save the whole array for repeated
 * accesses.  The intended implementation is that there is a strip buffer in
 * memory (as high as is possible given the desired memory limit), plus a
 * backing file that holds the rest of the array.
 *
 * The request_virt_array routines are told the total size of the image and
 * the maximum number of rows that will be accessed at once.  The in-memory
 * buffer must be at least as large as the maxaccess value.
 *
 * The request routines create control blocks but not the in-memory buffers.
 * That is postponed until realize_virt_arrays is called.  At that time the
 * total amount of space needed is known (approximately, anyway), so free
 * memory can be divided up fairly.
 *
 * The access_virt_array routines are responsible for making a specific strip
 * area accessible (after reading or writing the backing file, if necessary).
 * Note that the access routines are told whether the caller intends to modify
 * the accessed strip; during a read-only pass this saves having to rewrite
 * data to disk.  The access routines are also responsible for pre-zeroing
 * any newly accessed rows, if pre-zeroing was requested.
 *
 * In current usage, the access requests are usually for nonoverlapping
 * strips; that is, successive access start_row numbers differ by exactly
 * num_rows = maxaccess.  This means we can get good performance with simple
 * buffer dump/reload logic, by making the in-memory buffer be a multiple
 * of the access height; then there will never be accesses across bufferload
 * boundaries.  The code will still work with overlapping access requests,
 * but it doesn't handle bufferload overlaps very efficiently.
 */

unsafe extern "C" fn request_virt_sarray(
    mut cinfo: crate::jpeglib_h::j_common_ptr,
    mut pool_id: libc::c_int,
    mut pre_zero: crate::jmorecfg_h::boolean,
    mut samplesperrow: crate::jmorecfg_h::JDIMENSION,
    mut numrows: crate::jmorecfg_h::JDIMENSION,
    mut maxaccess: crate::jmorecfg_h::JDIMENSION,
) -> crate::jpeglib_h::jvirt_sarray_ptr
/* Request a virtual 2-D sample array */ {
    let mut mem: my_mem_ptr = (*cinfo).mem as my_mem_ptr;
    let mut result: crate::jpeglib_h::jvirt_sarray_ptr = 0 as *mut jvirt_sarray_control;
    /* Only IMAGE-lifetime virtual arrays are currently supported */
    if pool_id != crate::jpeglib_h::JPOOL_IMAGE {
        (*(*cinfo).err).msg_code = crate::src::jerror::JERR_BAD_POOL_ID as libc::c_int; /* safety check */
        (*(*cinfo).err).msg_parm.i[0 as libc::c_int as usize] = pool_id;
        Some(
            (*(*cinfo).err)
                .error_exit
                .expect("non-null function pointer"),
        )
        .expect("non-null function pointer")(cinfo);
    }
    /* get control block */
    result = alloc_small(
        cinfo,
        pool_id,
        ::std::mem::size_of::<jvirt_sarray_control>() as libc::c_ulong,
    ) as crate::jpeglib_h::jvirt_sarray_ptr; /* marks array not yet realized */
    (*result).mem_buffer = crate::stddef_h::NULL as crate::jpeglib_h::JSAMPARRAY; /* no associated backing-store object */
    (*result).rows_in_array = numrows; /* add to list of virtual arrays */
    (*result).samplesperrow = samplesperrow;
    (*result).maxaccess = maxaccess;
    (*result).pre_zero = pre_zero;
    (*result).b_s_open = crate::jmorecfg_h::FALSE;
    (*result).next = (*mem).virt_sarray_list;
    (*mem).virt_sarray_list = result;
    return result;
}

unsafe extern "C" fn request_virt_barray(
    mut cinfo: crate::jpeglib_h::j_common_ptr,
    mut pool_id: libc::c_int,
    mut pre_zero: crate::jmorecfg_h::boolean,
    mut blocksperrow: crate::jmorecfg_h::JDIMENSION,
    mut numrows: crate::jmorecfg_h::JDIMENSION,
    mut maxaccess: crate::jmorecfg_h::JDIMENSION,
) -> crate::jpeglib_h::jvirt_barray_ptr
/* Request a virtual 2-D coefficient-block array */ {
    let mut mem: my_mem_ptr = (*cinfo).mem as my_mem_ptr;
    let mut result: crate::jpeglib_h::jvirt_barray_ptr = 0 as *mut jvirt_barray_control;
    /* Only IMAGE-lifetime virtual arrays are currently supported */
    if pool_id != crate::jpeglib_h::JPOOL_IMAGE {
        (*(*cinfo).err).msg_code = crate::src::jerror::JERR_BAD_POOL_ID as libc::c_int; /* safety check */
        (*(*cinfo).err).msg_parm.i[0 as libc::c_int as usize] = pool_id;
        Some(
            (*(*cinfo).err)
                .error_exit
                .expect("non-null function pointer"),
        )
        .expect("non-null function pointer")(cinfo);
    }
    /* get control block */
    result = alloc_small(
        cinfo,
        pool_id,
        ::std::mem::size_of::<jvirt_barray_control>() as libc::c_ulong,
    ) as crate::jpeglib_h::jvirt_barray_ptr; /* marks array not yet realized */
    (*result).mem_buffer = crate::stddef_h::NULL as crate::jpeglib_h::JBLOCKARRAY; /* no associated backing-store object */
    (*result).rows_in_array = numrows; /* add to list of virtual arrays */
    (*result).blocksperrow = blocksperrow;
    (*result).maxaccess = maxaccess;
    (*result).pre_zero = pre_zero;
    (*result).b_s_open = crate::jmorecfg_h::FALSE;
    (*result).next = (*mem).virt_barray_list;
    (*mem).virt_barray_list = result;
    return result;
}

unsafe extern "C" fn realize_virt_arrays(mut cinfo: crate::jpeglib_h::j_common_ptr)
/* Allocate the in-memory buffers for any unrealized virtual arrays */
{
    let mut mem: my_mem_ptr = (*cinfo).mem as my_mem_ptr;
    let mut space_per_minheight: crate::stddef_h::size_t = 0;
    let mut maximum_space: crate::stddef_h::size_t = 0;
    let mut avail_mem: crate::stddef_h::size_t = 0;
    let mut minheights: crate::stddef_h::size_t = 0;
    let mut max_minheights: crate::stddef_h::size_t = 0;
    let mut sptr: crate::jpeglib_h::jvirt_sarray_ptr = 0 as *mut jvirt_sarray_control;
    let mut bptr: crate::jpeglib_h::jvirt_barray_ptr = 0 as *mut jvirt_barray_control;
    /* Compute the minimum space needed (maxaccess rows in each buffer)
     * and the maximum space needed (full image height in each buffer).
     * These may be of use to the system-dependent jpeg_mem_available routine.
     */
    space_per_minheight = 0 as libc::c_int as crate::stddef_h::size_t;
    maximum_space = 0 as libc::c_int as crate::stddef_h::size_t;
    sptr = (*mem).virt_sarray_list;
    while !sptr.is_null() {
        if (*sptr).mem_buffer.is_null() {
            /* if not realized yet */
            let mut new_space: crate::stddef_h::size_t = (((*sptr).rows_in_array as libc::c_long
                * (*sptr).samplesperrow as libc::c_long)
                as libc::c_ulong)
                .wrapping_mul(::std::mem::size_of::<crate::jmorecfg_h::JSAMPLE>() as libc::c_ulong);
            space_per_minheight = (space_per_minheight as libc::c_ulong).wrapping_add(
                (((*sptr).maxaccess as libc::c_long * (*sptr).samplesperrow as libc::c_long)
                    as libc::c_ulong)
                    .wrapping_mul(
                        ::std::mem::size_of::<crate::jmorecfg_h::JSAMPLE>() as libc::c_ulong
                    ),
            ) as crate::stddef_h::size_t
                as crate::stddef_h::size_t;
            if crate::stdlib::SIZE_MAX.wrapping_sub(maximum_space) < new_space {
                out_of_memory(cinfo, 10 as libc::c_int);
            }
            maximum_space = (maximum_space as libc::c_ulong).wrapping_add(new_space)
                as crate::stddef_h::size_t as crate::stddef_h::size_t
        }
        sptr = (*sptr).next
    }
    bptr = (*mem).virt_barray_list;
    while !bptr.is_null() {
        if (*bptr).mem_buffer.is_null() {
            /* if not realized yet */
            let mut new_space_0: crate::stddef_h::size_t = (((*bptr).rows_in_array as libc::c_long
                * (*bptr).blocksperrow as libc::c_long)
                as libc::c_ulong)
                .wrapping_mul(::std::mem::size_of::<crate::jpeglib_h::JBLOCK>() as libc::c_ulong); /* no unrealized arrays, no work */
            space_per_minheight = (space_per_minheight as libc::c_ulong).wrapping_add(
                (((*bptr).maxaccess as libc::c_long * (*bptr).blocksperrow as libc::c_long)
                    as libc::c_ulong)
                    .wrapping_mul(
                        ::std::mem::size_of::<crate::jpeglib_h::JBLOCK>() as libc::c_ulong
                    ),
            ) as crate::stddef_h::size_t
                as crate::stddef_h::size_t;
            if crate::stdlib::SIZE_MAX.wrapping_sub(maximum_space) < new_space_0 {
                out_of_memory(cinfo, 11 as libc::c_int);
            }
            maximum_space = (maximum_space as libc::c_ulong).wrapping_add(new_space_0)
                as crate::stddef_h::size_t as crate::stddef_h::size_t
        }
        bptr = (*bptr).next
    }
    if space_per_minheight <= 0 as libc::c_int as libc::c_ulong {
        return;
    }
    /* Determine amount of memory to actually use; this is system-dependent. */
    avail_mem = crate::src::jmemnobs::jpeg_mem_available(
        cinfo,
        space_per_minheight,
        maximum_space,
        (*mem).total_space_allocated,
    );
    /* If the maximum space needed is available, make all the buffers full
     * height; otherwise parcel it out with the same number of minheights
     * in each buffer.
     */
    if avail_mem >= maximum_space {
        max_minheights = 1000000000 as libc::c_long as crate::stddef_h::size_t
    } else {
        max_minheights = avail_mem.wrapping_div(space_per_minheight);
        /* If there doesn't seem to be enough space, try to get the minimum
         * anyway.  This allows a "stub" implementation of jpeg_mem_available().
         */
        if max_minheights <= 0 as libc::c_int as libc::c_ulong {
            max_minheights = 1 as libc::c_int as crate::stddef_h::size_t
        }
    }
    /* Allocate the in-memory buffers and initialize backing store as needed. */
    sptr = (*mem).virt_sarray_list;
    while !sptr.is_null() {
        if (*sptr).mem_buffer.is_null() {
            /* if not realized yet */
            minheights = (((*sptr).rows_in_array as libc::c_long - 1 as libc::c_long)
                / (*sptr).maxaccess as libc::c_long
                + 1 as libc::c_long) as crate::stddef_h::size_t;
            if minheights <= max_minheights {
                /* This buffer fits in memory */
                (*sptr).rows_in_mem = (*sptr).rows_in_array
            } else {
                /* It doesn't fit in memory, create backing store. */
                (*sptr).rows_in_mem = max_minheights
                    .wrapping_mul((*sptr).maxaccess as libc::c_ulong)
                    as crate::jmorecfg_h::JDIMENSION;
                crate::src::jmemnobs::jpeg_open_backing_store(
                    cinfo,
                    &mut (*sptr).b_s_info,
                    (*sptr).rows_in_array as libc::c_long
                        * (*sptr).samplesperrow as libc::c_long
                        * ::std::mem::size_of::<crate::jmorecfg_h::JSAMPLE>() as libc::c_ulong
                            as libc::c_long,
                );
                (*sptr).b_s_open = crate::jmorecfg_h::TRUE
            }
            (*sptr).mem_buffer = alloc_sarray(
                cinfo,
                crate::jpeglib_h::JPOOL_IMAGE,
                (*sptr).samplesperrow,
                (*sptr).rows_in_mem,
            );
            (*sptr).rowsperchunk = (*mem).last_rowsperchunk;
            (*sptr).cur_start_row = 0 as libc::c_int as crate::jmorecfg_h::JDIMENSION;
            (*sptr).first_undef_row = 0 as libc::c_int as crate::jmorecfg_h::JDIMENSION;
            (*sptr).dirty = crate::jmorecfg_h::FALSE
        }
        sptr = (*sptr).next
    }
    bptr = (*mem).virt_barray_list;
    while !bptr.is_null() {
        if (*bptr).mem_buffer.is_null() {
            /* if not realized yet */
            minheights = (((*bptr).rows_in_array as libc::c_long - 1 as libc::c_long)
                / (*bptr).maxaccess as libc::c_long
                + 1 as libc::c_long) as crate::stddef_h::size_t;
            if minheights <= max_minheights {
                /* This buffer fits in memory */
                (*bptr).rows_in_mem = (*bptr).rows_in_array
            } else {
                /* It doesn't fit in memory, create backing store. */
                (*bptr).rows_in_mem = max_minheights
                    .wrapping_mul((*bptr).maxaccess as libc::c_ulong)
                    as crate::jmorecfg_h::JDIMENSION;
                crate::src::jmemnobs::jpeg_open_backing_store(
                    cinfo,
                    &mut (*bptr).b_s_info,
                    (*bptr).rows_in_array as libc::c_long
                        * (*bptr).blocksperrow as libc::c_long
                        * ::std::mem::size_of::<crate::jpeglib_h::JBLOCK>() as libc::c_ulong
                            as libc::c_long,
                );
                (*bptr).b_s_open = crate::jmorecfg_h::TRUE
            }
            (*bptr).mem_buffer = alloc_barray(
                cinfo,
                crate::jpeglib_h::JPOOL_IMAGE,
                (*bptr).blocksperrow,
                (*bptr).rows_in_mem,
            );
            (*bptr).rowsperchunk = (*mem).last_rowsperchunk;
            (*bptr).cur_start_row = 0 as libc::c_int as crate::jmorecfg_h::JDIMENSION;
            (*bptr).first_undef_row = 0 as libc::c_int as crate::jmorecfg_h::JDIMENSION;
            (*bptr).dirty = crate::jmorecfg_h::FALSE
        }
        bptr = (*bptr).next
    }
}

unsafe extern "C" fn do_sarray_io(
    mut cinfo: crate::jpeglib_h::j_common_ptr,
    mut ptr: crate::jpeglib_h::jvirt_sarray_ptr,
    mut writing: crate::jmorecfg_h::boolean,
)
/* Do backing store read or write of a virtual sample array */
{
    let mut bytesperrow: libc::c_long = 0;
    let mut file_offset: libc::c_long = 0;
    let mut byte_count: libc::c_long = 0;
    let mut rows: libc::c_long = 0;
    let mut thisrow: libc::c_long = 0;
    let mut i: libc::c_long = 0;
    bytesperrow = ((*ptr).samplesperrow as libc::c_long as libc::c_ulong)
        .wrapping_mul(::std::mem::size_of::<crate::jmorecfg_h::JSAMPLE>() as libc::c_ulong)
        as libc::c_long;
    file_offset = (*ptr).cur_start_row as libc::c_long * bytesperrow;
    /* Loop to read or write each allocation chunk in mem_buffer */
    i = 0 as libc::c_int as libc::c_long;
    while i < (*ptr).rows_in_mem as libc::c_long {
        /* One chunk, but check for short chunk at end of buffer */
        rows = if ((*ptr).rowsperchunk as libc::c_long) < (*ptr).rows_in_mem as libc::c_long - i {
            (*ptr).rowsperchunk as libc::c_long
        } else {
            ((*ptr).rows_in_mem as libc::c_long) - i
        };
        /* Transfer no more than is currently defined */
        thisrow = (*ptr).cur_start_row as libc::c_long + i;
        rows = if rows < (*ptr).first_undef_row as libc::c_long - thisrow {
            rows
        } else {
            ((*ptr).first_undef_row as libc::c_long) - thisrow
        };
        /* Transfer no more than fits in file */
        rows = if rows < (*ptr).rows_in_array as libc::c_long - thisrow {
            rows
        } else {
            ((*ptr).rows_in_array as libc::c_long) - thisrow
        };
        if rows <= 0 as libc::c_int as libc::c_long {
            break;
        }
        byte_count = rows * bytesperrow;
        if writing != 0 {
            Some(
                (*ptr)
                    .b_s_info
                    .write_backing_store
                    .expect("non-null function pointer"),
            )
            .expect("non-null function pointer")(
                cinfo,
                &mut (*ptr).b_s_info,
                *(*ptr).mem_buffer.offset(i as isize) as *mut libc::c_void,
                file_offset,
                byte_count,
            );
        } else {
            Some(
                (*ptr)
                    .b_s_info
                    .read_backing_store
                    .expect("non-null function pointer"),
            )
            .expect("non-null function pointer")(
                cinfo,
                &mut (*ptr).b_s_info,
                *(*ptr).mem_buffer.offset(i as isize) as *mut libc::c_void,
                file_offset,
                byte_count,
            );
        }
        file_offset += byte_count;
        i += (*ptr).rowsperchunk as libc::c_long
    }
}

unsafe extern "C" fn do_barray_io(
    mut cinfo: crate::jpeglib_h::j_common_ptr,
    mut ptr: crate::jpeglib_h::jvirt_barray_ptr,
    mut writing: crate::jmorecfg_h::boolean,
)
/* Do backing store read or write of a virtual coefficient-block array */
{
    let mut bytesperrow: libc::c_long = 0;
    let mut file_offset: libc::c_long = 0;
    let mut byte_count: libc::c_long = 0;
    let mut rows: libc::c_long = 0;
    let mut thisrow: libc::c_long = 0;
    let mut i: libc::c_long = 0;
    bytesperrow = ((*ptr).blocksperrow as libc::c_long as libc::c_ulong)
        .wrapping_mul(::std::mem::size_of::<crate::jpeglib_h::JBLOCK>() as libc::c_ulong)
        as libc::c_long;
    file_offset = (*ptr).cur_start_row as libc::c_long * bytesperrow;
    /* Loop to read or write each allocation chunk in mem_buffer */
    i = 0 as libc::c_int as libc::c_long;
    while i < (*ptr).rows_in_mem as libc::c_long {
        /* One chunk, but check for short chunk at end of buffer */
        rows = if ((*ptr).rowsperchunk as libc::c_long) < (*ptr).rows_in_mem as libc::c_long - i {
            (*ptr).rowsperchunk as libc::c_long
        } else {
            ((*ptr).rows_in_mem as libc::c_long) - i
        };
        /* Transfer no more than is currently defined */
        thisrow = (*ptr).cur_start_row as libc::c_long + i;
        rows = if rows < (*ptr).first_undef_row as libc::c_long - thisrow {
            rows
        } else {
            ((*ptr).first_undef_row as libc::c_long) - thisrow
        };
        /* Transfer no more than fits in file */
        rows = if rows < (*ptr).rows_in_array as libc::c_long - thisrow {
            rows
        } else {
            ((*ptr).rows_in_array as libc::c_long) - thisrow
        };
        if rows <= 0 as libc::c_int as libc::c_long {
            break;
        }
        byte_count = rows * bytesperrow;
        if writing != 0 {
            Some(
                (*ptr)
                    .b_s_info
                    .write_backing_store
                    .expect("non-null function pointer"),
            )
            .expect("non-null function pointer")(
                cinfo,
                &mut (*ptr).b_s_info,
                *(*ptr).mem_buffer.offset(i as isize) as *mut libc::c_void,
                file_offset,
                byte_count,
            );
        } else {
            Some(
                (*ptr)
                    .b_s_info
                    .read_backing_store
                    .expect("non-null function pointer"),
            )
            .expect("non-null function pointer")(
                cinfo,
                &mut (*ptr).b_s_info,
                *(*ptr).mem_buffer.offset(i as isize) as *mut libc::c_void,
                file_offset,
                byte_count,
            );
        }
        file_offset += byte_count;
        i += (*ptr).rowsperchunk as libc::c_long
    }
}

unsafe extern "C" fn access_virt_sarray(
    mut cinfo: crate::jpeglib_h::j_common_ptr,
    mut ptr: crate::jpeglib_h::jvirt_sarray_ptr,
    mut start_row: crate::jmorecfg_h::JDIMENSION,
    mut num_rows: crate::jmorecfg_h::JDIMENSION,
    mut writable: crate::jmorecfg_h::boolean,
) -> crate::jpeglib_h::JSAMPARRAY
/* Access the part of a virtual sample array starting at start_row */
/* and extending for num_rows rows.  writable is true if  */
/* caller intends to modify the accessed area. */ {
    let mut end_row: crate::jmorecfg_h::JDIMENSION = start_row.wrapping_add(num_rows);
    let mut undef_row: crate::jmorecfg_h::JDIMENSION = 0;
    /* debugging check */
    if end_row > (*ptr).rows_in_array || num_rows > (*ptr).maxaccess || (*ptr).mem_buffer.is_null()
    {
        (*(*cinfo).err).msg_code = crate::src::jerror::JERR_BAD_VIRTUAL_ACCESS as libc::c_int;
        Some(
            (*(*cinfo).err)
                .error_exit
                .expect("non-null function pointer"),
        )
        .expect("non-null function pointer")(cinfo);
    }
    /* Make the desired part of the virtual array accessible */
    if start_row < (*ptr).cur_start_row
        || end_row > (*ptr).cur_start_row.wrapping_add((*ptr).rows_in_mem)
    {
        if (*ptr).b_s_open == 0 {
            (*(*cinfo).err).msg_code = crate::src::jerror::JERR_VIRTUAL_BUG as libc::c_int;
            Some(
                (*(*cinfo).err)
                    .error_exit
                    .expect("non-null function pointer"),
            )
            .expect("non-null function pointer")(cinfo);
        }
        /* Flush old buffer contents if necessary */
        if (*ptr).dirty != 0 {
            do_sarray_io(cinfo, ptr, crate::jmorecfg_h::TRUE);
            (*ptr).dirty = crate::jmorecfg_h::FALSE
        }
        /* Decide what part of virtual array to access.
         * Algorithm: if target address > current window, assume forward scan,
         * load starting at target address.  If target address < current window,
         * assume backward scan, load so that target area is top of window.
         * Note that when switching from forward write to forward read, will have
         * start_row = 0, so the limiting case applies and we load from 0 anyway.
         */
        if start_row > (*ptr).cur_start_row {
            (*ptr).cur_start_row = start_row
        } else {
            /* use long arithmetic here to avoid overflow & unsigned problems */
            let mut ltemp: libc::c_long = 0; /* don't fall off front end of file */
            ltemp = end_row as libc::c_long - (*ptr).rows_in_mem as libc::c_long;
            if ltemp < 0 as libc::c_int as libc::c_long {
                ltemp = 0 as libc::c_int as libc::c_long
            }
            (*ptr).cur_start_row = ltemp as crate::jmorecfg_h::JDIMENSION
        }
        /* Read in the selected part of the array.
         * During the initial write pass, we will do no actual read
         * because the selected part is all undefined.
         */
        do_sarray_io(cinfo, ptr, crate::jmorecfg_h::FALSE);
    }
    /* Ensure the accessed part of the array is defined; prezero if needed.
     * To improve locality of access, we only prezero the part of the array
     * that the caller is about to access, not the entire in-memory array.
     */
    if (*ptr).first_undef_row < end_row {
        if (*ptr).first_undef_row < start_row {
            if writable != 0 {
                /* writer skipped over a section of array */
                (*(*cinfo).err).msg_code =
                    crate::src::jerror::JERR_BAD_VIRTUAL_ACCESS as libc::c_int;
                Some(
                    (*(*cinfo).err)
                        .error_exit
                        .expect("non-null function pointer"),
                )
                .expect("non-null function pointer")(cinfo);
            }
            undef_row = start_row
        /* but reader is allowed to read ahead */
        } else {
            undef_row = (*ptr).first_undef_row
        } /* make indexes relative to buffer */
        if writable != 0 {
            (*ptr).first_undef_row = end_row
        }
        if (*ptr).pre_zero != 0 {
            let mut bytesperrow: crate::stddef_h::size_t = ((*ptr).samplesperrow
                as crate::stddef_h::size_t)
                .wrapping_mul(::std::mem::size_of::<crate::jmorecfg_h::JSAMPLE>() as libc::c_ulong);
            undef_row = (undef_row as libc::c_uint).wrapping_sub((*ptr).cur_start_row)
                as crate::jmorecfg_h::JDIMENSION
                as crate::jmorecfg_h::JDIMENSION;
            end_row = (end_row as libc::c_uint).wrapping_sub((*ptr).cur_start_row)
                as crate::jmorecfg_h::JDIMENSION
                as crate::jmorecfg_h::JDIMENSION;
            while undef_row < end_row {
                crate::src::jutils::jzero_far(
                    *(*ptr).mem_buffer.offset(undef_row as isize) as *mut libc::c_void,
                    bytesperrow,
                );
                undef_row = undef_row.wrapping_add(1)
            }
        } else if writable == 0 {
            /* reader looking at undefined data */
            (*(*cinfo).err).msg_code = crate::src::jerror::JERR_BAD_VIRTUAL_ACCESS as libc::c_int;
            Some(
                (*(*cinfo).err)
                    .error_exit
                    .expect("non-null function pointer"),
            )
            .expect("non-null function pointer")(cinfo);
        }
    }
    /* Flag the buffer dirty if caller will write in it */
    if writable != 0 {
        (*ptr).dirty = crate::jmorecfg_h::TRUE
    }
    /* Return address of proper part of the buffer */
    return (*ptr)
        .mem_buffer
        .offset(start_row.wrapping_sub((*ptr).cur_start_row) as isize);
}

unsafe extern "C" fn access_virt_barray(
    mut cinfo: crate::jpeglib_h::j_common_ptr,
    mut ptr: crate::jpeglib_h::jvirt_barray_ptr,
    mut start_row: crate::jmorecfg_h::JDIMENSION,
    mut num_rows: crate::jmorecfg_h::JDIMENSION,
    mut writable: crate::jmorecfg_h::boolean,
) -> crate::jpeglib_h::JBLOCKARRAY
/* Access the part of a virtual block array starting at start_row */
/* and extending for num_rows rows.  writable is true if  */
/* caller intends to modify the accessed area. */ {
    let mut end_row: crate::jmorecfg_h::JDIMENSION = start_row.wrapping_add(num_rows);
    let mut undef_row: crate::jmorecfg_h::JDIMENSION = 0;
    /* debugging check */
    if end_row > (*ptr).rows_in_array || num_rows > (*ptr).maxaccess || (*ptr).mem_buffer.is_null()
    {
        (*(*cinfo).err).msg_code = crate::src::jerror::JERR_BAD_VIRTUAL_ACCESS as libc::c_int;
        Some(
            (*(*cinfo).err)
                .error_exit
                .expect("non-null function pointer"),
        )
        .expect("non-null function pointer")(cinfo);
    }
    /* Make the desired part of the virtual array accessible */
    if start_row < (*ptr).cur_start_row
        || end_row > (*ptr).cur_start_row.wrapping_add((*ptr).rows_in_mem)
    {
        if (*ptr).b_s_open == 0 {
            (*(*cinfo).err).msg_code = crate::src::jerror::JERR_VIRTUAL_BUG as libc::c_int;
            Some(
                (*(*cinfo).err)
                    .error_exit
                    .expect("non-null function pointer"),
            )
            .expect("non-null function pointer")(cinfo);
        }
        /* Flush old buffer contents if necessary */
        if (*ptr).dirty != 0 {
            do_barray_io(cinfo, ptr, crate::jmorecfg_h::TRUE);
            (*ptr).dirty = crate::jmorecfg_h::FALSE
        }
        /* Decide what part of virtual array to access.
         * Algorithm: if target address > current window, assume forward scan,
         * load starting at target address.  If target address < current window,
         * assume backward scan, load so that target area is top of window.
         * Note that when switching from forward write to forward read, will have
         * start_row = 0, so the limiting case applies and we load from 0 anyway.
         */
        if start_row > (*ptr).cur_start_row {
            (*ptr).cur_start_row = start_row
        } else {
            /* use long arithmetic here to avoid overflow & unsigned problems */
            let mut ltemp: libc::c_long = 0; /* don't fall off front end of file */
            ltemp = end_row as libc::c_long - (*ptr).rows_in_mem as libc::c_long;
            if ltemp < 0 as libc::c_int as libc::c_long {
                ltemp = 0 as libc::c_int as libc::c_long
            }
            (*ptr).cur_start_row = ltemp as crate::jmorecfg_h::JDIMENSION
        }
        /* Read in the selected part of the array.
         * During the initial write pass, we will do no actual read
         * because the selected part is all undefined.
         */
        do_barray_io(cinfo, ptr, crate::jmorecfg_h::FALSE);
    }
    /* Ensure the accessed part of the array is defined; prezero if needed.
     * To improve locality of access, we only prezero the part of the array
     * that the caller is about to access, not the entire in-memory array.
     */
    if (*ptr).first_undef_row < end_row {
        if (*ptr).first_undef_row < start_row {
            if writable != 0 {
                /* writer skipped over a section of array */
                (*(*cinfo).err).msg_code =
                    crate::src::jerror::JERR_BAD_VIRTUAL_ACCESS as libc::c_int;
                Some(
                    (*(*cinfo).err)
                        .error_exit
                        .expect("non-null function pointer"),
                )
                .expect("non-null function pointer")(cinfo);
            }
            undef_row = start_row
        /* but reader is allowed to read ahead */
        } else {
            undef_row = (*ptr).first_undef_row
        } /* make indexes relative to buffer */
        if writable != 0 {
            (*ptr).first_undef_row = end_row
        }
        if (*ptr).pre_zero != 0 {
            let mut bytesperrow: crate::stddef_h::size_t = ((*ptr).blocksperrow
                as crate::stddef_h::size_t)
                .wrapping_mul(::std::mem::size_of::<crate::jpeglib_h::JBLOCK>() as libc::c_ulong);
            undef_row = (undef_row as libc::c_uint).wrapping_sub((*ptr).cur_start_row)
                as crate::jmorecfg_h::JDIMENSION
                as crate::jmorecfg_h::JDIMENSION;
            end_row = (end_row as libc::c_uint).wrapping_sub((*ptr).cur_start_row)
                as crate::jmorecfg_h::JDIMENSION
                as crate::jmorecfg_h::JDIMENSION;
            while undef_row < end_row {
                crate::src::jutils::jzero_far(
                    *(*ptr).mem_buffer.offset(undef_row as isize) as *mut libc::c_void,
                    bytesperrow,
                );
                undef_row = undef_row.wrapping_add(1)
            }
        } else if writable == 0 {
            /* reader looking at undefined data */
            (*(*cinfo).err).msg_code = crate::src::jerror::JERR_BAD_VIRTUAL_ACCESS as libc::c_int;
            Some(
                (*(*cinfo).err)
                    .error_exit
                    .expect("non-null function pointer"),
            )
            .expect("non-null function pointer")(cinfo);
        }
    }
    /* Flag the buffer dirty if caller will write in it */
    if writable != 0 {
        (*ptr).dirty = crate::jmorecfg_h::TRUE
    }
    /* Return address of proper part of the buffer */
    return (*ptr)
        .mem_buffer
        .offset(start_row.wrapping_sub((*ptr).cur_start_row) as isize);
}
/*
 * Release all objects belonging to a specified pool.
 */

unsafe extern "C" fn free_pool(
    mut cinfo: crate::jpeglib_h::j_common_ptr,
    mut pool_id: libc::c_int,
) {
    let mut mem: my_mem_ptr = (*cinfo).mem as my_mem_ptr; /* safety check */
    let mut shdr_ptr: small_pool_ptr = 0 as *mut small_pool_struct;
    let mut lhdr_ptr: large_pool_ptr = 0 as *mut large_pool_struct;
    let mut space_freed: crate::stddef_h::size_t = 0;
    if pool_id < 0 as libc::c_int || pool_id >= crate::jpeglib_h::JPOOL_NUMPOOLS {
        (*(*cinfo).err).msg_code = crate::src::jerror::JERR_BAD_POOL_ID as libc::c_int;
        (*(*cinfo).err).msg_parm.i[0 as libc::c_int as usize] = pool_id;
        Some(
            (*(*cinfo).err)
                .error_exit
                .expect("non-null function pointer"),
        )
        .expect("non-null function pointer")(cinfo);
    }
    /* If freeing IMAGE pool, close any virtual arrays first */
    if pool_id == crate::jpeglib_h::JPOOL_IMAGE {
        let mut sptr: crate::jpeglib_h::jvirt_sarray_ptr = 0 as *mut jvirt_sarray_control;
        let mut bptr: crate::jpeglib_h::jvirt_barray_ptr = 0 as *mut jvirt_barray_control;
        sptr = (*mem).virt_sarray_list;
        while !sptr.is_null() {
            if (*sptr).b_s_open != 0 {
                /* there may be no backing store */
                (*sptr).b_s_open = crate::jmorecfg_h::FALSE; /* prevent recursive close if error */
                Some(
                    (*sptr)
                        .b_s_info
                        .close_backing_store
                        .expect("non-null function pointer"),
                )
                .expect("non-null function pointer")(cinfo, &mut (*sptr).b_s_info);
            }
            sptr = (*sptr).next
        }
        (*mem).virt_sarray_list = crate::stddef_h::NULL as crate::jpeglib_h::jvirt_sarray_ptr;
        bptr = (*mem).virt_barray_list;
        while !bptr.is_null() {
            if (*bptr).b_s_open != 0 {
                /* there may be no backing store */
                (*bptr).b_s_open = crate::jmorecfg_h::FALSE; /* prevent recursive close if error */
                Some(
                    (*bptr)
                        .b_s_info
                        .close_backing_store
                        .expect("non-null function pointer"),
                )
                .expect("non-null function pointer")(cinfo, &mut (*bptr).b_s_info);
            }
            bptr = (*bptr).next
        }
        (*mem).virt_barray_list = crate::stddef_h::NULL as crate::jpeglib_h::jvirt_barray_ptr
    }
    /* Release large objects */
    lhdr_ptr = (*mem).large_list[pool_id as usize];
    (*mem).large_list[pool_id as usize] = crate::stddef_h::NULL as large_pool_ptr;
    while !lhdr_ptr.is_null() {
        let mut next_lhdr_ptr: large_pool_ptr = (*lhdr_ptr).next;
        space_freed = (*lhdr_ptr)
            .bytes_used
            .wrapping_add((*lhdr_ptr).bytes_left)
            .wrapping_add(::std::mem::size_of::<large_pool_hdr>() as libc::c_ulong);
        crate::src::jmemnobs::jpeg_free_large(cinfo, lhdr_ptr as *mut libc::c_void, space_freed);
        (*mem).total_space_allocated =
            ((*mem).total_space_allocated as libc::c_ulong).wrapping_sub(space_freed)
                as crate::stddef_h::size_t as crate::stddef_h::size_t;
        lhdr_ptr = next_lhdr_ptr
    }
    /* Release small objects */
    shdr_ptr = (*mem).small_list[pool_id as usize];
    (*mem).small_list[pool_id as usize] = crate::stddef_h::NULL as small_pool_ptr;
    while !shdr_ptr.is_null() {
        let mut next_shdr_ptr: small_pool_ptr = (*shdr_ptr).next;
        space_freed = (*shdr_ptr)
            .bytes_used
            .wrapping_add((*shdr_ptr).bytes_left)
            .wrapping_add(::std::mem::size_of::<small_pool_hdr>() as libc::c_ulong);
        crate::src::jmemnobs::jpeg_free_small(cinfo, shdr_ptr as *mut libc::c_void, space_freed);
        (*mem).total_space_allocated =
            ((*mem).total_space_allocated as libc::c_ulong).wrapping_sub(space_freed)
                as crate::stddef_h::size_t as crate::stddef_h::size_t;
        shdr_ptr = next_shdr_ptr
    }
}
/*
 * Close up shop entirely.
 * Note that this cannot be called unless cinfo->mem is non-NULL.
 */

unsafe extern "C" fn self_destruct(mut cinfo: crate::jpeglib_h::j_common_ptr) {
    let mut pool: libc::c_int = 0;
    /* Close all backing store, release all memory.
     * Releasing pools in reverse order might help avoid fragmentation
     * with some (brain-damaged) malloc libraries.
     */
    pool = crate::jpeglib_h::JPOOL_NUMPOOLS - 1 as libc::c_int;
    while pool >= crate::jpeglib_h::JPOOL_PERMANENT {
        free_pool(cinfo, pool);
        pool -= 1
    }
    /* Release the memory manager control block too. */
    crate::src::jmemnobs::jpeg_free_small(
        cinfo,
        (*cinfo).mem as *mut libc::c_void,
        ::std::mem::size_of::<my_memory_mgr>() as libc::c_ulong,
    ); /* ensures I will be called only once */
    (*cinfo).mem = crate::stddef_h::NULL as *mut crate::jpeglib_h::jpeg_memory_mgr;
    crate::src::jmemnobs::jpeg_mem_term(cinfo);
    /* system-dependent cleanup */
}
/*
 * Memory manager initialization.
 * When this is called, only the error manager pointer is valid in cinfo!
 */
#[no_mangle]

pub unsafe extern "C" fn jinit_memory_mgr(mut cinfo: crate::jpeglib_h::j_common_ptr) {
    let mut mem: my_mem_ptr = 0 as *mut my_memory_mgr; /* for safety if init fails */
    let mut max_to_use: libc::c_long = 0;
    let mut pool: libc::c_int = 0;
    let mut test_mac: crate::stddef_h::size_t = 0;
    (*cinfo).mem = crate::stddef_h::NULL as *mut crate::jpeglib_h::jpeg_memory_mgr;
    /* Check for configuration errors.
     * sizeof(ALIGN_TYPE) should be a power of 2; otherwise, it probably
     * doesn't reflect any real hardware alignment requirement.
     * The test is a little tricky: for X>0, X and X-1 have no one-bits
     * in common if and only if X is a power of 2, ie has only one one-bit.
     * Some compilers may give an "unreachable code" warning here; ignore it.
     */
    if ALIGN_SIZE & ALIGN_SIZE - 1 as libc::c_int != 0 as libc::c_int {
        (*(*cinfo).err).msg_code = crate::src::jerror::JERR_BAD_ALIGN_TYPE as libc::c_int;
        Some(
            (*(*cinfo).err)
                .error_exit
                .expect("non-null function pointer"),
        )
        .expect("non-null function pointer")(cinfo);
    }
    /* MAX_ALLOC_CHUNK must be representable as type size_t, and must be
     * a multiple of ALIGN_SIZE.
     * Again, an "unreachable code" warning may be ignored here.
     * But a "constant too large" warning means you need to fix MAX_ALLOC_CHUNK.
     */
    test_mac = crate::jmemsys_h::MAX_ALLOC_CHUNK as crate::stddef_h::size_t; /* system-dependent initialization */
    if test_mac as libc::c_long != crate::jmemsys_h::MAX_ALLOC_CHUNK
        || crate::jmemsys_h::MAX_ALLOC_CHUNK % ALIGN_SIZE as libc::c_long
            != 0 as libc::c_int as libc::c_long
    {
        (*(*cinfo).err).msg_code = crate::src::jerror::JERR_BAD_ALLOC_CHUNK as libc::c_int;
        Some(
            (*(*cinfo).err)
                .error_exit
                .expect("non-null function pointer"),
        )
        .expect("non-null function pointer")(cinfo);
    }
    max_to_use = crate::src::jmemnobs::jpeg_mem_init(cinfo);
    /* Attempt to allocate memory manager's control block */
    mem = crate::src::jmemnobs::jpeg_get_small(
        cinfo,
        ::std::mem::size_of::<my_memory_mgr>() as libc::c_ulong,
    ) as my_mem_ptr; /* system-dependent cleanup */
    if mem.is_null() {
        crate::src::jmemnobs::jpeg_mem_term(cinfo);
        (*(*cinfo).err).msg_code = crate::src::jerror::JERR_OUT_OF_MEMORY as libc::c_int;
        (*(*cinfo).err).msg_parm.i[0 as libc::c_int as usize] = 0 as libc::c_int;
        Some(
            (*(*cinfo).err)
                .error_exit
                .expect("non-null function pointer"),
        )
        .expect("non-null function pointer")(cinfo);
    }
    /* OK, fill in the method pointers */
    (*mem).pub_0.alloc_small = Some(
        alloc_small
            as unsafe extern "C" fn(
                _: crate::jpeglib_h::j_common_ptr,
                _: libc::c_int,
                _: crate::stddef_h::size_t,
            ) -> *mut libc::c_void,
    );
    (*mem).pub_0.alloc_large = Some(
        alloc_large
            as unsafe extern "C" fn(
                _: crate::jpeglib_h::j_common_ptr,
                _: libc::c_int,
                _: crate::stddef_h::size_t,
            ) -> *mut libc::c_void,
    );
    (*mem).pub_0.alloc_sarray = Some(
        alloc_sarray
            as unsafe extern "C" fn(
                _: crate::jpeglib_h::j_common_ptr,
                _: libc::c_int,
                _: crate::jmorecfg_h::JDIMENSION,
                _: crate::jmorecfg_h::JDIMENSION,
            ) -> crate::jpeglib_h::JSAMPARRAY,
    );
    (*mem).pub_0.alloc_barray = Some(
        alloc_barray
            as unsafe extern "C" fn(
                _: crate::jpeglib_h::j_common_ptr,
                _: libc::c_int,
                _: crate::jmorecfg_h::JDIMENSION,
                _: crate::jmorecfg_h::JDIMENSION,
            ) -> crate::jpeglib_h::JBLOCKARRAY,
    );
    (*mem).pub_0.request_virt_sarray = Some(
        request_virt_sarray
            as unsafe extern "C" fn(
                _: crate::jpeglib_h::j_common_ptr,
                _: libc::c_int,
                _: crate::jmorecfg_h::boolean,
                _: crate::jmorecfg_h::JDIMENSION,
                _: crate::jmorecfg_h::JDIMENSION,
                _: crate::jmorecfg_h::JDIMENSION,
            ) -> crate::jpeglib_h::jvirt_sarray_ptr,
    );
    (*mem).pub_0.request_virt_barray = Some(
        request_virt_barray
            as unsafe extern "C" fn(
                _: crate::jpeglib_h::j_common_ptr,
                _: libc::c_int,
                _: crate::jmorecfg_h::boolean,
                _: crate::jmorecfg_h::JDIMENSION,
                _: crate::jmorecfg_h::JDIMENSION,
                _: crate::jmorecfg_h::JDIMENSION,
            ) -> crate::jpeglib_h::jvirt_barray_ptr,
    );
    (*mem).pub_0.realize_virt_arrays =
        Some(realize_virt_arrays as unsafe extern "C" fn(_: crate::jpeglib_h::j_common_ptr) -> ());
    (*mem).pub_0.access_virt_sarray = Some(
        access_virt_sarray
            as unsafe extern "C" fn(
                _: crate::jpeglib_h::j_common_ptr,
                _: crate::jpeglib_h::jvirt_sarray_ptr,
                _: crate::jmorecfg_h::JDIMENSION,
                _: crate::jmorecfg_h::JDIMENSION,
                _: crate::jmorecfg_h::boolean,
            ) -> crate::jpeglib_h::JSAMPARRAY,
    );
    (*mem).pub_0.access_virt_barray = Some(
        access_virt_barray
            as unsafe extern "C" fn(
                _: crate::jpeglib_h::j_common_ptr,
                _: crate::jpeglib_h::jvirt_barray_ptr,
                _: crate::jmorecfg_h::JDIMENSION,
                _: crate::jmorecfg_h::JDIMENSION,
                _: crate::jmorecfg_h::boolean,
            ) -> crate::jpeglib_h::JBLOCKARRAY,
    );
    (*mem).pub_0.free_pool = Some(
        free_pool as unsafe extern "C" fn(_: crate::jpeglib_h::j_common_ptr, _: libc::c_int) -> (),
    );
    (*mem).pub_0.self_destruct =
        Some(self_destruct as unsafe extern "C" fn(_: crate::jpeglib_h::j_common_ptr) -> ());
    /* Make MAX_ALLOC_CHUNK accessible to other modules */
    (*mem).pub_0.max_alloc_chunk = crate::jmemsys_h::MAX_ALLOC_CHUNK;
    /* Initialize working state */
    (*mem).pub_0.max_memory_to_use = max_to_use;
    pool = crate::jpeglib_h::JPOOL_NUMPOOLS - 1 as libc::c_int;
    while pool >= crate::jpeglib_h::JPOOL_PERMANENT {
        (*mem).small_list[pool as usize] = crate::stddef_h::NULL as small_pool_ptr;
        (*mem).large_list[pool as usize] = crate::stddef_h::NULL as large_pool_ptr;
        pool -= 1
    }
    (*mem).virt_sarray_list = crate::stddef_h::NULL as crate::jpeglib_h::jvirt_sarray_ptr;
    (*mem).virt_barray_list = crate::stddef_h::NULL as crate::jpeglib_h::jvirt_barray_ptr;
    (*mem).total_space_allocated = ::std::mem::size_of::<my_memory_mgr>() as libc::c_ulong;
    /* Declare ourselves open for business */
    (*cinfo).mem = &mut (*mem).pub_0;
    /* Check for an environment variable JPEGMEM; if found, override the
     * default max_memory setting from jpeg_mem_init.  Note that the
     * surrounding application may again override this value.
     * If your system doesn't support getenv(), define NO_GETENV to disable
     * this feature.
     */
    let mut memenv: *mut libc::c_char = 0 as *mut libc::c_char;
    memenv = crate::stdlib::getenv(b"JPEGMEM\x00" as *const u8 as *const libc::c_char);
    if !memenv.is_null() {
        let mut ch: libc::c_char = 'x' as i32 as libc::c_char;
        if crate::stdlib::sscanf(
            memenv,
            b"%ld%c\x00" as *const u8 as *const libc::c_char,
            &mut max_to_use as *mut libc::c_long,
            &mut ch as *mut libc::c_char,
        ) > 0 as libc::c_int
        {
            if ch as libc::c_int == 'm' as i32 || ch as libc::c_int == 'M' as i32 {
                max_to_use *= 1000 as libc::c_long
            }
            (*mem).pub_0.max_memory_to_use = max_to_use * 1000 as libc::c_long
        }
    };
}
